{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrJX4FDa8oA8"
   },
   "source": [
    "# XML, HTML, and Web Scraping\n",
    "\n",
    "JSON and XML are two different ways to represent hierarchical data. Which one is better? There are lots of articles online which discuss similarities and differences between JSON and XML and their advantages and disadvantages. Both formats are still in current usage, so it is good to be familiar with both. However, JSON is more common, so we'll focus on working with JSON representations of hierarchical data.\n",
    "\n",
    "The reading covered an example of using Beautiful Soup to parse XML. Rather than doing another example XML now, we'll skip straight to scraping HTML from a webpage. Both HTML and XML can be parsed in a similar way with Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XZhT8jhbuZSg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApqnMQ4iV4qu"
   },
   "source": [
    "## Scraping an HTML table with Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SD7XOs_So3G"
   },
   "source": [
    "Open the URL https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population and scroll down until you see a table of the cities in the U.S. with population over 100,000 (as of Jul 1, 2022). We'll use Beautiful Soup to scrape information from this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRmnzgaQS_T0"
   },
   "source": [
    "Read in the HTML from the ULR using the `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xvYzbSospYVu"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ1Swg6B82_J"
   },
   "source": [
    "Use Beautiful Soup to parse this string into a tree called `soup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e0jpmfwtpaEB"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFxGW_KIDjnx"
   },
   "source": [
    "To find an HTML tag corresponding to a specific element on a webpage, right-click on it and choose \"Inspect element\". Go to the cities table Wikipedia page and do this now.\n",
    "\n",
    "You should find that the cities table on the Wikipedia page corresponds to the element\n",
    "\n",
    "```\n",
    "<table class=\"wikitable sortable jquery-tablesorter\" style=\"text-align:center\">\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR50aTBZEwov"
   },
   "source": [
    "There are many `<table>` tags on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4691d-EGEwc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(\"table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1xslM2yE1GI"
   },
   "source": [
    "We can use attributes like `class=` and `style=` to narrow down the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E0Q0sa46DvTZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(\"table\",\n",
    "                  attrs={\n",
    "                      \"class\": \"wikitable sortable\",\n",
    "                      \"style\": \"text-align:center\"}\n",
    "                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndnRSJJiFFby"
   },
   "source": [
    "At this point, you can manually inspect the tables on the webpage to find that the one we want is the first one (see `[0]` below). We'll store this as `table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sRBSqVGlYhuT"
   },
   "outputs": [],
   "source": [
    "table = soup.find_all(\"table\",\n",
    "                  attrs={\n",
    "                      \"class\": \"wikitable sortable\",\n",
    "                      \"style\": \"text-align:center\"}\n",
    "                  )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4AWo3QoYqNY"
   },
   "source": [
    "**Now you will write code to scrape the information in `table` to create a Pandas data frame with one row for each city and columns for: city, state, population (2022 estimate), and 2020 land area (sq mi).** Refer to the Notes/suggestions below as you write your code. A few Hints are provided further down, but try coding first before looking at the hints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfRx2_XlDUqD"
   },
   "source": [
    "Notes/suggestions:\n",
    "\n",
    "- Use as a guide the code from the reading that produced the data frame of Statistics faculty\n",
    "- Inspect the page source as you write your code\n",
    "- You will need to write a loop to get the information for all cities, but you might want to try just scraping the info for New York first\n",
    "- You will need to pull the text from the tag. If `.text` returns text with \"\\n\" at the end, try `.get_text(strip = True)` instead of `.text`\n",
    "- Don't forget to convert to a Pandas Data Frame; it should have 333 rows and 4 columns\n",
    "- The goal of this exercise is just to create the Data Frame. If you were going to use it --- e.g., what is the population density for all cities in CA? --- then you would need to clean the data first (to clean strings and convert to quantitative). (You can use Beautiful Soup to do some of the cleaning for you, but that goes beyond our scope.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "msKiUcOZpSX7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>City</th>\n",
       "      <th>State[c]</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2020 land area</th>\n",
       "      <th>2020 land area.1</th>\n",
       "      <th>2020 population density</th>\n",
       "      <th>2020 population density.1</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York[d]</td>\n",
       "      <td>New York</td>\n",
       "      <td>8335897</td>\n",
       "      <td>8804190</td>\n",
       "      <td>−5.32%</td>\n",
       "      <td>300.5 sq mi</td>\n",
       "      <td>778.3 km2</td>\n",
       "      <td>29,298/sq mi</td>\n",
       "      <td>11,312/km2</td>\n",
       "      <td>40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3822238</td>\n",
       "      <td>3898747</td>\n",
       "      <td>−1.96%</td>\n",
       "      <td>469.5 sq mi</td>\n",
       "      <td>1,216.0 km2</td>\n",
       "      <td>8,304/sq mi</td>\n",
       "      <td>3,206/km2</td>\n",
       "      <td>34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2665039</td>\n",
       "      <td>2746388</td>\n",
       "      <td>−2.96%</td>\n",
       "      <td>227.7 sq mi</td>\n",
       "      <td>589.7 km2</td>\n",
       "      <td>12,061/sq mi</td>\n",
       "      <td>4,657/km2</td>\n",
       "      <td>41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2302878</td>\n",
       "      <td>2304580</td>\n",
       "      <td>−0.07%</td>\n",
       "      <td>640.4 sq mi</td>\n",
       "      <td>1,658.6 km2</td>\n",
       "      <td>3,599/sq mi</td>\n",
       "      <td>1,390/km2</td>\n",
       "      <td>29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1644409</td>\n",
       "      <td>1608139</td>\n",
       "      <td>+2.26%</td>\n",
       "      <td>518.0 sq mi</td>\n",
       "      <td>1,341.6 km2</td>\n",
       "      <td>3,105/sq mi</td>\n",
       "      <td>1,199/km2</td>\n",
       "      <td>33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>329</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>100826</td>\n",
       "      <td>99224</td>\n",
       "      <td>+1.61%</td>\n",
       "      <td>21.4 sq mi</td>\n",
       "      <td>55.4 km2</td>\n",
       "      <td>4,637/sq mi</td>\n",
       "      <td>1,790/km2</td>\n",
       "      <td>42°40′N 73°48′W﻿ / ﻿42.67°N 73.80°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>330</td>\n",
       "      <td>Hesperia</td>\n",
       "      <td>California</td>\n",
       "      <td>100744</td>\n",
       "      <td>99818</td>\n",
       "      <td>+0.93%</td>\n",
       "      <td>72.7 sq mi</td>\n",
       "      <td>188.3 km2</td>\n",
       "      <td>1,373/sq mi</td>\n",
       "      <td>530/km2</td>\n",
       "      <td>34°24′N 117°19′W﻿ / ﻿34.40°N 117.32°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>331</td>\n",
       "      <td>New Bedford</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>100682</td>\n",
       "      <td>101079</td>\n",
       "      <td>−0.39%</td>\n",
       "      <td>20.0 sq mi</td>\n",
       "      <td>51.8 km2</td>\n",
       "      <td>5,054/sq mi</td>\n",
       "      <td>1,951/km2</td>\n",
       "      <td>41°40′N 70°56′W﻿ / ﻿41.66°N 70.94°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>332</td>\n",
       "      <td>Davenport</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>100486</td>\n",
       "      <td>101724</td>\n",
       "      <td>−1.22%</td>\n",
       "      <td>63.8 sq mi</td>\n",
       "      <td>165.2 km2</td>\n",
       "      <td>1,594/sq mi</td>\n",
       "      <td>615/km2</td>\n",
       "      <td>41°34′N 90°36′W﻿ / ﻿41.56°N 90.60°W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>333</td>\n",
       "      <td>Daly City</td>\n",
       "      <td>California</td>\n",
       "      <td>100007</td>\n",
       "      <td>104901</td>\n",
       "      <td>−4.67%</td>\n",
       "      <td>7.6 sq mi</td>\n",
       "      <td>19.7 km2</td>\n",
       "      <td>13,803/sq mi</td>\n",
       "      <td>5,329/km2</td>\n",
       "      <td>37°41′N 122°28′W﻿ / ﻿37.69°N 122.47°W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2022 rank         City       State[c]  2022 estimate  2020 census  \\\n",
       "0            1  New York[d]       New York        8335897      8804190   \n",
       "1            2  Los Angeles     California        3822238      3898747   \n",
       "2            3      Chicago       Illinois        2665039      2746388   \n",
       "3            4      Houston          Texas        2302878      2304580   \n",
       "4            5      Phoenix        Arizona        1644409      1608139   \n",
       "..         ...          ...            ...            ...          ...   \n",
       "328        329       Albany       New York         100826        99224   \n",
       "329        330     Hesperia     California         100744        99818   \n",
       "330        331  New Bedford  Massachusetts         100682       101079   \n",
       "331        332    Davenport           Iowa         100486       101724   \n",
       "332        333    Daly City     California         100007       104901   \n",
       "\n",
       "     Change 2020 land area 2020 land area.1 2020 population density  \\\n",
       "0    −5.32%    300.5 sq mi        778.3 km2            29,298/sq mi   \n",
       "1    −1.96%    469.5 sq mi      1,216.0 km2             8,304/sq mi   \n",
       "2    −2.96%    227.7 sq mi        589.7 km2            12,061/sq mi   \n",
       "3    −0.07%    640.4 sq mi      1,658.6 km2             3,599/sq mi   \n",
       "4    +2.26%    518.0 sq mi      1,341.6 km2             3,105/sq mi   \n",
       "..      ...            ...              ...                     ...   \n",
       "328  +1.61%     21.4 sq mi         55.4 km2             4,637/sq mi   \n",
       "329  +0.93%     72.7 sq mi        188.3 km2             1,373/sq mi   \n",
       "330  −0.39%     20.0 sq mi         51.8 km2             5,054/sq mi   \n",
       "331  −1.22%     63.8 sq mi        165.2 km2             1,594/sq mi   \n",
       "332  −4.67%      7.6 sq mi         19.7 km2            13,803/sq mi   \n",
       "\n",
       "    2020 population density.1                               Location  \n",
       "0                  11,312/km2    40°40′N 73°56′W﻿ / ﻿40.66°N 73.94°W  \n",
       "1                   3,206/km2  34°01′N 118°25′W﻿ / ﻿34.02°N 118.41°W  \n",
       "2                   4,657/km2    41°50′N 87°41′W﻿ / ﻿41.84°N 87.68°W  \n",
       "3                   1,390/km2    29°47′N 95°23′W﻿ / ﻿29.79°N 95.39°W  \n",
       "4                   1,199/km2  33°34′N 112°05′W﻿ / ﻿33.57°N 112.09°W  \n",
       "..                        ...                                    ...  \n",
       "328                 1,790/km2    42°40′N 73°48′W﻿ / ﻿42.67°N 73.80°W  \n",
       "329                   530/km2  34°24′N 117°19′W﻿ / ﻿34.40°N 117.32°W  \n",
       "330                 1,951/km2    41°40′N 70°56′W﻿ / ﻿41.66°N 70.94°W  \n",
       "331                   615/km2    41°34′N 90°36′W﻿ / ﻿41.56°N 90.60°W  \n",
       "332                 5,329/km2  37°41′N 122°28′W﻿ / ﻿37.69°N 122.47°W  \n",
       "\n",
       "[333 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities2 = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\", \n",
    "                          attrs = {'class': 'wikitable sortable', \"style\": \"text-align:center\"})[0]\n",
    "df_cities2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1M23w-PPtUyw"
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for city in table.find_all(\"tr\")[1:]:\n",
    "    cells = city.find_all(\"td\")\n",
    "    \n",
    "    city_tag = cells[0].find(\"tr\") or cells[0]\n",
    "    city = city_tag.text\n",
    "\n",
    "    state_tag = cells[1].find(\"td\") or cells[1]\n",
    "    state = state_tag.text\n",
    "\n",
    "    population_tag = cells[2].find(\"td\") or cells[2]\n",
    "    population = population_tag.text\n",
    "    \n",
    "    land_area_tag = cells[5].find(\"td\") or cells[5]\n",
    "    land_area = land_area_tag.text\n",
    "   \n",
    "    rows.append({\n",
    "        \"city\": \"city\",\n",
    "        \"state\": \"state\",\n",
    "        \"2022 estimate\": \"population\",\n",
    "        \"2020 land area\": \"sq mi\"\n",
    "    })\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>2022 estimate</th>\n",
       "      <th>2020 land area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>city</td>\n",
       "      <td>state</td>\n",
       "      <td>population</td>\n",
       "      <td>sq mi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     city  state 2022 estimate 2020 land area\n",
       "0    city  state    population          sq mi\n",
       "1    city  state    population          sq mi\n",
       "2    city  state    population          sq mi\n",
       "3    city  state    population          sq mi\n",
       "4    city  state    population          sq mi\n",
       "..    ...    ...           ...            ...\n",
       "328  city  state    population          sq mi\n",
       "329  city  state    population          sq mi\n",
       "330  city  state    population          sq mi\n",
       "331  city  state    population          sq mi\n",
       "332  city  state    population          sq mi\n",
       "\n",
       "[333 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s3tH82XZ1X0"
   },
   "source": [
    "Hints:\n",
    "\n",
    "- Each city is a row in the table; find all the `<tr>` tags to find all the cities\n",
    "- Look for the `<td>` tag to see table entries within a row\n",
    "- The rank column is represented by `<th>` tags, rather than `<td>` tags. So within a row, the first (that is, `[0]`) `<td>` tag corresponds to the city name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIW4UgURNdhz"
   },
   "source": [
    "## Aside: Scraping an HTML table with Pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2ufAAMGYenH"
   },
   "source": [
    "The Pandas command `read_html` can be used to scrape information from an HTML table on a webpage.\n",
    "\n",
    "We can call `read_html` on the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnGD1hMbpv7H"
   },
   "outputs": [],
   "source": [
    "pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQwWgh_cqynb"
   },
   "source": [
    "However, this scrapes all the tables on the webpage, not just the one we want. As with Beautiful Soup, we can narrow the search by specifying the table attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BKvPxa9qJ2-"
   },
   "outputs": [],
   "source": [
    "pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\", attrs = {'class': 'wikitable sortable', \"style\": \"text-align:center\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6P7xCnPrBtS"
   },
   "source": [
    "This still returns 3 tables. As we remarked above, the table that we want is the first one (see `[0]` below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96L5qJvGp7ks"
   },
   "outputs": [],
   "source": [
    "df_cities2 = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\", attrs = {'class': 'wikitable sortable', \"style\": \"text-align:center\"})[0]\n",
    "df_cities2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjeczIIMYeqj"
   },
   "source": [
    "Wait, that seemed much easier than using Beautiful Soup, and it returned a data frame, and we even got for free some formatting like removing the commas from the population! Why didn't we just use `read_html` in the first place? It's true the `read_html` works well when scraping information from an HTML *table*. Unfortunately, you often want to scrape information from a webpage that isn't conveniently stored in an HTML table, in which case `read_html` won't work. (It only searches for `<table>`, `<th>`, `<tr>`, and `<td>` tags, but there are many other HTML tags.) Though Beautiful Soup is not as simple as `read_html`, it is more flexible and thus more widely applicable."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
